# ğŸ›°ï¸ Domain-Specific Q&A Assistant

This project implements a **retrieval-augmented generation (RAG)** chatbot designed to answer domain-specific technical questions based on internal documents.  
It leverages **LangChain**, **FAISS**, and **Hugging Face Transformers** to deliver fast, accurate, and context-aware responses.

---

## âœ¨ Features

âœ… End-to-end RAG pipeline using LangChain  
âœ… Local GPU-accelerated LLM inference (Flan-T5)  
âœ… Semantic search with SentenceTransformers + FAISS vector store  
âœ… Streamlit web app for interactive Q&A  
âœ… CLI interface for terminal-based interaction  
âœ… Modular design supporting local and cloud backends

---

## ğŸ—ï¸ Architecture Overview

- **Data ingestion** â†’ Structured and unstructured `.txt` files are embedded using `sentence-transformers/all-MiniLM-L6-v2`.
- **Vector storage** â†’ FAISS provides a high-speed local vector store for semantic retrieval.
- **LLM backend** â†’ Local Hugging Face model (`google/flan-t5-base`) runs on GPU for fast, cost-free inference.
- **Orchestration** â†’ LangChain connects the retriever and generator into a unified RAG pipeline.
- **Frontend** â†’ Streamlit provides an interactive web UI; CLI mode is also supported.

---

## ğŸ› ï¸ Setup Instructions

1ï¸âƒ£ **Clone the repo**
```bash
git clone https://github.com/elaminemouhamadali/domain-qa-assistant.git
cd domain-qa-assistant
